{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AI2FC - GİRİŞ 1",
      "provenance": [],
      "collapsed_sections": [
        "Y7QKrre2wOVg"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVbGIpYzVuBO"
      },
      "source": [
        "from google.colab import drive  \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7QKrre2wOVg"
      },
      "source": [
        "## Aİ2FC - RETİNANET MODELİ İçin Colab Kullanımı ve Temel Bilgiler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHaKSKYk6ygw"
      },
      "source": [
        "##Doğrulama İşlemi\n",
        "\"\"\" from google.colab import drive\n",
        "* drive.mount('/gdrive')\n",
        "* %cd /gdrive\n",
        "\"\"\"\n",
        "##Kütüphane Kurulumu\n",
        "\"\"\"\n",
        "*!pip install - q keras #örnek keras kurulumu\n",
        "*!apt -get install graphviz -y #bir diğer örnek kütüphane graphviz\n",
        "*import keras #kütüphane import aşaması\n",
        "\"\"\"\n",
        "## Donanım Türünün Belirlenmesi\n",
        "\"\"\"\n",
        "*GPU ve TPU iki seçeneği vardır.\n",
        "Yukarıda ki \n",
        "*Çalışma zamana >> Çalışma zamanı türünü değiştir\n",
        "*GPU veya tpu seç\n",
        "\"\"\"\n",
        "##Donanım Türü ve Versiyonunu görmek İçin\n",
        "\"\"\"\n",
        "import tensorflow_hub as hub\n",
        "print(\"TF version:\",tf.__version__)\n",
        "print(\"Hub version:\"+hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"Not avaliable\")\n",
        "\"\"\"\n",
        "##Colabta Kulalnılan GPU modelini Görmek için \n",
        "\"\"\"\n",
        "*from tensorflow.python.client import device_lib\n",
        "*device_lib_list_local_device()\n",
        "\"\"\"\n",
        "##Python Kodunun Colabta Çalıştırılması\n",
        "\"\"\"\n",
        "=>Dizin kontrolü yapılır.\n",
        "*!ls\n",
        "*Eğer ki colabta yüklediğiniz dosyayla aynı dizindeyseniz\n",
        "*!python3 dosya-adi.py ile kodu çalıştırın\"\"\"\n",
        "#DAHA FAZLASI İÇİN https://rahul-metangale.medium.com/google-colaboratory-cheat-sheet-24b99813b0f0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaNTmv475iGq"
      },
      "source": [
        "#Dosya Silme Nasıl Yapılır ? \n",
        "#!rm -r dosya_adi "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvDlefxtoyke"
      },
      "source": [
        "#Çevre Bileşenlerinin Kurulumu Aşamaları\n",
        "* Seçilen reponun colab üzerine klonlanması (https://github.com/fizyr/keras-retinanet.git)\n",
        "* Kütüphanelerin Kurulumu ve İmport edilmesi\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1D1HSF4-PUi"
      },
      "source": [
        "!git clone https://github.com/fizyr/keras-retinanet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzihBeRY7Cg_"
      },
      "source": [
        "!rm -r sample_data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP8CbO_r-dvN"
      },
      "source": [
        "%cd keras-retinanet/ \n",
        "!pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXlGfIvZ-mJJ"
      },
      "source": [
        "!python setup.py build_ext --inplace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIlKjB2R-nM4"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import xml.etree.ElementTree as ET\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas\n",
        "from google.colab import drive\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall keras -y \n",
        "!pip uninstall keras-nightly -y \n",
        "!pip uninstall keras-Preprocessing -y \n",
        "!pip uninstall keras-vis -y \n",
        "!pip uninstall tensorflow -y"
      ],
      "metadata": {
        "id": "FgeIJFAiC8qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYPq5NQ_31I2"
      },
      "source": [
        "s!pip install tensorflow==2.3.0 \n",
        "!pip install keras==2.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxGlnr4qsMUU"
      },
      "source": [
        "#Veri Setinin Hazırlanması\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVdE5vJNfcqR"
      },
      "source": [
        "#dosyaların oluşturulması\n",
        "DATASET_DIR = 'veriseti'\n",
        "ANNOTATIONS_FILE = 'annotations.csv'\n",
        "CLASSES_FILE = 'classes.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM-bu4KUfc2n"
      },
      "source": [
        "#zipin içerisinden çıkarılan dosyanın adının \"veriseti\" olarak değiştirilmesi gerekiyor\n",
        "#verisetinin indirilmesi\n",
        "import shutil\n",
        "shutil.copy(\"/content/drive/MyDrive/2020-2021 Yarışması/verisetison.zip\",\"/content/keras-retinanet/\")\n",
        "#os.rename(r'veri',r'veriseti')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86oD_jxfV-PD"
      },
      "source": [
        "#!rm -rf veriseti"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJvUAtI6VFxv"
      },
      "source": [
        "os.rename(r'verisetison',r'veriseti')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efc3HbnGgrLG"
      },
      "source": [
        "annotations = []\n",
        "classes = set([])\n",
        "\n",
        "for xml_file in [f for f in os.listdir(DATASET_DIR) if f.endswith(\".xml\")]:\n",
        "  tree = ET.parse(os.path.join(DATASET_DIR, xml_file))\n",
        "  root = tree.getroot()\n",
        "\n",
        "  file_name = None\n",
        "\n",
        "  for elem in root:\n",
        "    if elem.tag == 'filename':\n",
        "      file_name = os.path.join(DATASET_DIR, elem.text)\n",
        "\n",
        "    if elem.tag == 'object':\n",
        "      obj_name = None\n",
        "      coords = []\n",
        "      for subelem in elem:\n",
        "        if subelem.tag == 'name':\n",
        "          obj_name = subelem.text\n",
        "        if subelem.tag == 'bndbox':\n",
        "          xmin = \"\"\n",
        "          xmax = \"\"\n",
        "          ymin = \"\"\n",
        "          ymax = \"\"\n",
        "          for subsubelem in subelem:\n",
        "            f = float(subsubelem.text)\n",
        "            i = int(f)\n",
        "            if subsubelem.tag == \"xmin\":\n",
        "              xmin = str(i)\n",
        "            if subsubelem.tag == \"xmax\":\n",
        "              xmax = str(i)\n",
        "            if subsubelem.tag == \"ymin\":\n",
        "              ymin = str(i)\n",
        "            if subsubelem.tag == \"ymax\":\n",
        "              ymax = str(i)\n",
        "          \n",
        "          coords.append(xmin)\n",
        "          coords.append(ymin)\n",
        "          coords.append(xmax)\n",
        "          coords.append(ymax)\n",
        "            \n",
        "      item = [file_name] + coords + [obj_name]\n",
        "      annotations.append(item)\n",
        "      classes.add(obj_name)\n",
        "\n",
        "with open(ANNOTATIONS_FILE, 'w') as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerows(annotations)\n",
        "\n",
        "with open(CLASSES_FILE, 'w') as f:\n",
        "  for i, line in enumerate(classes):\n",
        "\n",
        "    f.write('{},{}\\n'.format(line,i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlpNdvr26ohj"
      },
      "source": [
        "#Modelin Eğitilmesi(Training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfRbhYaDjrAn"
      },
      "source": [
        "#%cd /content/keras-retinanet/veriseti"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF_mPhEzjwwz"
      },
      "source": [
        "#os.rename(r'3 (141).xml',r'a.xml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pny18N9rlxIk"
      },
      "source": [
        "#!rm a.xml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r temp.zip keras-retinanet/ "
      ],
      "metadata": {
        "id": "5NsaVrJjPjCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prqXDbQEl9vC"
      },
      "source": [
        "#%cd /content/keras-retinanet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DucQn_zs8Oc"
      },
      "source": [
        "PRETRAINED_MODEL = './snapshots/_pretrained_model.h5'\n",
        "URL_MODEL = 'https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5'\n",
        "urllib.request.urlretrieve(URL_MODEL, PRETRAINED_MODEL)\n",
        "print('Downloaded pretrained model to ' + PRETRAINED_MODEL)\n",
        "!keras_retinanet/bin/train.py --freeze-backbone --random-transform --weights {PRETRAINED_MODEL} --batch-size 10 --steps 700  --epochs 3 csv annotations.csv classes.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN8SX8WOVsXe"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw53HDhtkBHo"
      },
      "source": [
        "#### Modeli Drive Çıkarma ####\n",
        "drive.mount('/content/gdrive')\n",
        "COLAB_MODEL = './snapshots/resnet50_csv_10.h5'\n",
        "DRIVE_DIR = '/content/gdrive/My Drive/Colab Notebooks/'\n",
        "shutil.copy(COLAB_MODEL, DRIVE_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etTQHXlPr_Je"
      },
      "source": [
        "# Modelin Google Drive Üzerinden Çekilerek LİNKEDİN Paylaşımı İçin Test Edilmesi [1 kereye mahsus]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbZRncShsB-j"
      },
      "source": [
        "#### Modeli Drivedan çekme ####\n",
        "!gdown https://drive.google.com/uc?id=1MNgd4wRjNJyxr1XiKvICYgO1y-BiHq4Z\n",
        "shutil.copy(\"/content/drive/MyDrive/2020-2021 Yarışması/15epoch_10batch_700steps_18haziran.h5\",\"/content/keras-retinanet/snapshots\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzX1QTCykoWL"
      },
      "source": [
        "#Çıkarım - Test(İnference)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy(\"/content/drive/MyDrive/2020-2021 Yarışması/17epoch_10batch_700steps_18haziran.h5\",\"/content/keras-retinanet/snapshots\")"
      ],
      "metadata": {
        "id": "-ElwlmejA9qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJxYgOlbkzer"
      },
      "source": [
        "THRES_SCORE = 0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHfkn0nxk9c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0c8316-1c52-47eb-fb19-045b53b5d9c8"
      },
      "source": [
        "# show images inline\n",
        "%matplotlib inline\n",
        "\n",
        "# automatically reload modules when they have changed\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# import keras\n",
        "import keras\n",
        "\n",
        "# import keras_retinanet\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color\n",
        "\n",
        "# import miscellaneous modules\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# set tf backend to allow memory to grow, instead of claiming everything\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "%cd /content/keras-retinanet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_0igYjfCa6c",
        "outputId": "fb0675b7-238e-4ba1-957f-c31cc8cacd03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/keras-retinanet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.19.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "5WN4-C5yCVv2",
        "outputId": "1edf9a03-efde-48ef-dcfa-52238bdadb02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.19.5\n",
            "  Using cached numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.3.0 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.19.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyxdameraulevenshtein==1.5.3\n",
        "!pip install pandas==1.1.4  \n",
        "!pip install scikit-learn==0.20.2\n",
        "!pip install Numpy==1.16.1\n",
        "#Works well in Python3.6, Issue in Python3.7."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vyK6BmNWDZVT",
        "outputId": "62b43314-908b-464e-f2ce-90bcba416b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyxdameraulevenshtein==1.5.3\n",
            "  Downloading pyxDamerauLevenshtein-1.5.3.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 3.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.7/dist-packages (from pyxdameraulevenshtein==1.5.3) (1.19.5)\n",
            "Building wheels for collected packages: pyxdameraulevenshtein\n",
            "  Building wheel for pyxdameraulevenshtein (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyxdameraulevenshtein: filename=pyxDamerauLevenshtein-1.5.3-cp37-cp37m-linux_x86_64.whl size=88235 sha256=2982bf23fb13fdb3a97eda0f99ae0d60e42454d0b85a8ee8bd049b206fbd01ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/51/91/3fcd99c9ac5d66dee56560ae19d106668c84fa8c2e42e23e7f\n",
            "Successfully built pyxdameraulevenshtein\n",
            "Installing collected packages: pyxdameraulevenshtein\n",
            "Successfully installed pyxdameraulevenshtein-1.5.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas==1.1.4\n",
            "  Downloading pandas-1.1.4-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.4) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.4) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.4) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.1.4) (1.15.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "Successfully installed pandas-1.1.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn==0.20.2\n",
            "  Downloading scikit_learn-0.20.2-cp37-cp37m-manylinux1_x86_64.whl (5.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.4 MB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.20.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.20.2) (1.19.5)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.20.2 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.20.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.20.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Numpy==1.16.1\n",
            "  Downloading numpy-1.16.1-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 527 kB/s \n",
            "\u001b[?25hInstalling collected packages: Numpy\n",
            "  Attempting uninstall: Numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.20.2 which is incompatible.\n",
            "xarray 0.20.2 requires numpy>=1.18, but you have numpy 1.16.1 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.16.1 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.16.1 which is incompatible.\n",
            "scikit-image 0.18.3 requires numpy>=1.16.5, but you have numpy 1.16.1 which is incompatible.\n",
            "pywavelets 1.3.0 requires numpy>=1.17.3, but you have numpy 1.16.1 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.16.1 which is incompatible.\n",
            "pyarrow 6.0.1 requires numpy>=1.16.6, but you have numpy 1.16.1 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.16.1 which is incompatible.\n",
            "jaxlib 0.3.7+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.16.1 which is incompatible.\n",
            "jax 0.3.8 requires numpy>=1.19, but you have numpy 1.16.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.20.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cupy-cuda111 9.4.0 requires numpy<1.24,>=1.17, but you have numpy 1.16.1 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.16.1 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Numpy-1.16.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9GTCHN7k-wa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "outputId": "7642894c-0e31-4bfa-ae3a-0499f809ed32"
      },
      "source": [
        "model_path = os.path.join('snapshots/', sorted(os.listdir('snapshots'), reverse=True)[0])\n",
        "print(model_path)\n",
        "\n",
        "# load retinanet model\n",
        "model = models.load_model(model_path, backbone_name='resnet50')\n",
        "model = models.convert_model(model)\n",
        "\n",
        "# load label to names mapping for visualization purposes\n",
        "labels_to_names = pandas.read_csv(CLASSES_FILE,header=None).T.loc[0].to_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[autoreload of numpy.lib failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "NameError: name 'type_check' is not defined\n",
            "]\n",
            "[autoreload of numpy.matrixlib failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "NameError: name 'defmatrix' is not defined\n",
            "]\n",
            "[autoreload of numpy.linalg.linalg failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ValueError: Only callable can be used as callback\n",
            "]\n",
            "[autoreload of numpy.testing failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "NameError: name '_private' is not defined\n",
            "]\n",
            "[autoreload of numpy.testing._private.utils failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "AttributeError: module 'numpy.linalg' has no attribute 'lapack_lite'\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "snapshots/_pretrained_model.h5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-82b3cc86ab1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load retinanet model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackbone_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resnet50'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/keras-retinanet/keras_retinanet/models/__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, backbone_name)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/keras-retinanet/keras_retinanet/models/__init__.py\u001b[0m in \u001b[0;36mbackbone\u001b[0;34m(backbone_name)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeBackbone\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m'resnet'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackbone_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNetBackbone\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m'mobilenet'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackbone_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmobilenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMobileNetBackbone\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/keras-retinanet/keras_retinanet/models/resnet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_resnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mretinanet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/keras-retinanet/keras_retinanet/models/retinanet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnchorParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0massert_training_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/keras-retinanet/keras_retinanet/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_misc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRegressBoxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUpsampleLike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAnchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClipBoxes\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfilter_detections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFilterDetections\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/keras-retinanet/keras_retinanet/layers/_misc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manchors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils_anchors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/keras-retinanet/keras_retinanet/utils/anchors.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_overlap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_overlap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/keras-retinanet/keras_retinanet/utils/compute_overlap.pyx\u001b[0m in \u001b[0;36minit keras_retinanet.utils.compute_overlap\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;31m# --------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Fast R-CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Copyright (c) 2015 Microsoft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Licensed under The MIT License [see LICENSE for details]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Written by Sergey Karayev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JseBvwTWlLdC"
      },
      "source": [
        "def img_inference(img_path):\n",
        "  image = read_image_bgr(img_infer)\n",
        "\n",
        "  # copy to draw on\n",
        "  draw = image.copy()\n",
        "  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # preprocess image for network\n",
        "  image = preprocess_image(image)\n",
        "  image, scale = resize_image(image)\n",
        "\n",
        "  # process image\n",
        "  start = time.time()\n",
        "  boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "  print(\"processing time: \", time.time() - start)\n",
        "\n",
        "  # correct for image scale\n",
        "  boxes /= scale\n",
        "\n",
        "  # visualize detections\n",
        "  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "      # scores are sorted so we can break\n",
        "      if score < THRES_SCORE:\n",
        "          break\n",
        "\n",
        "      color = label_color(label)\n",
        "\n",
        "      b = box.astype(int)\n",
        "      draw_box(draw, b, color=color)\n",
        "\n",
        "      caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
        "      draw_caption(draw, b, caption)\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(draw)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VlMJ0jalS0S"
      },
      "source": [
        "uploaded = files.upload()\n",
        "img_infer = list(uploaded)[0]\n",
        "\n",
        "print('Running inference on: ' + img_infer)\n",
        "img_inference(img_infer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4LJN9D05pfts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1Wq1nAfiqHad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/keras-retinanet"
      ],
      "metadata": {
        "id": "abFS7yFgqHyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W1rYoRSWqIqw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}